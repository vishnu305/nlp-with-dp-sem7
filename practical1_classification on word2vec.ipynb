{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>urgency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connection issues with assigned address hi fac...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cannot access hi cannot access fallowing link ...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re address shown valid dear colleagues remarke...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sent tuesday critical alert following alert oc...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code spelling mistake hello should discover fo...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual leave hello sent last week about previo...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>report working hello dear last two weeks have ...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>more access lost access please reset password ...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open credentials required please assist instal...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dear please ask our supplier for price quotati...</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body urgency\n",
       "0  connection issues with assigned address hi fac...      P1\n",
       "1  cannot access hi cannot access fallowing link ...      P2\n",
       "2  re address shown valid dear colleagues remarke...      P1\n",
       "3  sent tuesday critical alert following alert oc...      P2\n",
       "4  code spelling mistake hello should discover fo...      P2\n",
       "5  annual leave hello sent last week about previo...      P2\n",
       "6  report working hello dear last two weeks have ...      P2\n",
       "7  more access lost access please reset password ...      P1\n",
       "8  open credentials required please assist instal...      P1\n",
       "9  dear please ask our supplier for price quotati...      P2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reading the data\n",
    "TicketData=pd.read_csv('supportTicketData.csv')\n",
    "\n",
    "# Printing number of rows and columns\n",
    "print(TicketData.shape)\n",
    "\n",
    "# Printing sample rows\n",
    "TicketData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urgency\n",
      "P1    6748\n",
      "P2    5528\n",
      "P3    7520\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of unique values for urgency column\n",
    "# You can see there are 3 ticket types\n",
    "print(TicketData.groupby('urgency').size())\n",
    "\n",
    "# Plotting the bar chart\n",
    "%matplotlib inline\n",
    "TicketData.groupby('urgency').size().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19796, 9100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abeam</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>...</th>\n",
       "      <th>zig</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ab  abandon  abandoned  abc  abeam  abilities  ability  able  abnormal  \\\n",
       "0   0        0          0    0      0          0        0     0         0   \n",
       "1   0        0          0    0      0          0        0     0         0   \n",
       "2   0        0          0    0      0          0        0     0         0   \n",
       "3   0        0          0    0      0          0        0     0         0   \n",
       "4   0        0          0    0      0          0        0     0         0   \n",
       "\n",
       "   abnormally  ...  zig  zip  zipped  zipper  zipping  zone  zones  zoom  \\\n",
       "0           0  ...    0    0       0       0        0     0      0     0   \n",
       "1           0  ...    0    0       0       0        0     0      0     0   \n",
       "2           0  ...    0    0       0       0        0     0      0     0   \n",
       "3           0  ...    0    0       0       0        0     0      0     0   \n",
       "4           0  ...    0    0       0       0        0     0      0     0   \n",
       "\n",
       "   zooming  Priority  \n",
       "0        0        P1  \n",
       "1        0        P2  \n",
       "2        0        P1  \n",
       "3        0        P2  \n",
       "4        0        P2  \n",
       "\n",
       "[5 rows x 9100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Ticket Data\n",
    "corpus = TicketData['body'].values\n",
    "\n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "CountVectorizedData['Priority']=TicketData['urgency']\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec conversion:\n",
    "Now we will use the Word2Vec representation of words to convert the above document term matrix to a smaller matrix, where the columns are the sum of the vectors for each word present in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will Use the Pre-trained word2Vec model from google, It contains word vectors for a vocabulary of 3 million words.\n",
    "Trained on around 100 billion words from the google news dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#Loading the word vectors from Google trained word2Vec model\n",
    "GoogleModel = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each word is a vector of 300 numbers\n",
    "GoogleModel['hello'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05419922,  0.01708984, -0.00527954,  0.33203125, -0.25      ,\n",
       "       -0.01397705, -0.15039062, -0.265625  ,  0.01647949,  0.3828125 ,\n",
       "       -0.03295898, -0.09716797, -0.16308594, -0.04443359,  0.00946045,\n",
       "        0.18457031,  0.03637695,  0.16601562,  0.36328125, -0.25585938,\n",
       "        0.375     ,  0.171875  ,  0.21386719, -0.19921875,  0.13085938,\n",
       "       -0.07275391, -0.02819824,  0.11621094,  0.15332031,  0.09082031,\n",
       "        0.06787109, -0.0300293 , -0.16894531, -0.20800781, -0.03710938,\n",
       "       -0.22753906,  0.26367188,  0.012146  ,  0.18359375,  0.31054688,\n",
       "       -0.10791016, -0.19140625,  0.21582031,  0.13183594, -0.03515625,\n",
       "        0.18554688, -0.30859375,  0.04785156, -0.10986328,  0.14355469,\n",
       "       -0.43554688, -0.0378418 ,  0.10839844,  0.140625  , -0.10595703,\n",
       "        0.26171875, -0.17089844,  0.39453125,  0.12597656, -0.27734375,\n",
       "       -0.28125   ,  0.14746094, -0.20996094,  0.02355957,  0.18457031,\n",
       "        0.00445557, -0.27929688, -0.03637695, -0.29296875,  0.19628906,\n",
       "        0.20703125,  0.2890625 , -0.20507812,  0.06787109, -0.43164062,\n",
       "       -0.10986328, -0.2578125 , -0.02331543,  0.11328125,  0.23144531,\n",
       "       -0.04418945,  0.10839844, -0.2890625 , -0.09521484, -0.10351562,\n",
       "       -0.0324707 ,  0.07763672, -0.13378906,  0.22949219,  0.06298828,\n",
       "        0.08349609,  0.02929688, -0.11474609,  0.00534058, -0.12988281,\n",
       "        0.02514648,  0.08789062,  0.24511719, -0.11474609, -0.296875  ,\n",
       "       -0.59375   , -0.29492188, -0.13378906,  0.27734375, -0.04174805,\n",
       "        0.11621094,  0.28320312,  0.00241089,  0.13867188, -0.00683594,\n",
       "       -0.30078125,  0.16210938,  0.01171875, -0.13867188,  0.48828125,\n",
       "        0.02880859,  0.02416992,  0.04736328,  0.05859375, -0.23828125,\n",
       "        0.02758789,  0.05981445, -0.03857422,  0.06933594,  0.14941406,\n",
       "       -0.10888672, -0.07324219,  0.08789062,  0.27148438,  0.06591797,\n",
       "       -0.37890625, -0.26171875, -0.13183594,  0.09570312, -0.3125    ,\n",
       "        0.10205078,  0.03063965,  0.23632812,  0.00582886,  0.27734375,\n",
       "        0.20507812, -0.17871094, -0.31445312, -0.01586914,  0.13964844,\n",
       "        0.13574219,  0.0390625 , -0.29296875,  0.234375  , -0.33984375,\n",
       "       -0.11816406,  0.10644531, -0.18457031, -0.02099609,  0.02563477,\n",
       "        0.25390625,  0.07275391,  0.13574219, -0.00138092, -0.2578125 ,\n",
       "       -0.2890625 ,  0.10107422,  0.19238281, -0.04882812,  0.27929688,\n",
       "       -0.3359375 , -0.07373047,  0.01879883, -0.10986328, -0.04614258,\n",
       "        0.15722656,  0.06689453, -0.03417969,  0.16308594,  0.08642578,\n",
       "        0.44726562,  0.02026367, -0.01977539,  0.07958984,  0.17773438,\n",
       "       -0.04370117, -0.00952148,  0.16503906,  0.17285156,  0.23144531,\n",
       "       -0.04272461,  0.02355957,  0.18359375, -0.41601562, -0.01745605,\n",
       "        0.16796875,  0.04736328,  0.14257812,  0.08496094,  0.33984375,\n",
       "        0.1484375 , -0.34375   , -0.14160156, -0.06835938, -0.14648438,\n",
       "       -0.02844238,  0.07421875, -0.07666016,  0.12695312,  0.05859375,\n",
       "       -0.07568359, -0.03344727,  0.23632812, -0.16308594,  0.16503906,\n",
       "        0.1484375 , -0.2421875 , -0.3515625 , -0.30664062,  0.00491333,\n",
       "        0.17675781,  0.46289062,  0.14257812, -0.25      , -0.25976562,\n",
       "        0.04370117,  0.34960938,  0.05957031,  0.07617188, -0.02868652,\n",
       "       -0.09667969, -0.01281738,  0.05859375, -0.22949219, -0.1953125 ,\n",
       "       -0.12207031,  0.20117188, -0.42382812,  0.06005859,  0.50390625,\n",
       "        0.20898438,  0.11230469, -0.06054688,  0.33203125,  0.07421875,\n",
       "       -0.05786133,  0.11083984, -0.06494141,  0.05639648,  0.01757812,\n",
       "        0.08398438,  0.13769531,  0.2578125 ,  0.16796875, -0.16894531,\n",
       "        0.01794434,  0.16015625,  0.26171875,  0.31640625, -0.24804688,\n",
       "        0.05371094, -0.0859375 ,  0.17089844, -0.39453125, -0.00156403,\n",
       "       -0.07324219, -0.04614258, -0.16210938, -0.15722656,  0.21289062,\n",
       "       -0.15820312,  0.04394531,  0.28515625,  0.01196289, -0.26953125,\n",
       "       -0.04370117,  0.37109375,  0.04663086, -0.19726562,  0.3046875 ,\n",
       "       -0.36523438, -0.23632812,  0.08056641, -0.04248047, -0.14648438,\n",
       "       -0.06225586, -0.0534668 , -0.05664062,  0.18945312,  0.37109375,\n",
       "       -0.22070312,  0.04638672,  0.02612305, -0.11474609,  0.265625  ,\n",
       "       -0.02453613,  0.11083984, -0.02514648, -0.12060547,  0.05297852,\n",
       "        0.07128906,  0.00063705, -0.36523438, -0.13769531, -0.12890625],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleModel['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding similar words\n",
    "# The most_similar() function finds the cosine similarity of the given word with \n",
    "# other words using the word2Vec representations of each word\n",
    "GoogleModel.most_similar('king', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if a word is present in the Model Vocabulary\n",
    "'Hello' in GoogleModel.key_to_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ab', 'abandon', 'abandoned', 'abc', 'abeam', 'abilities', 'ability',\n",
       "       'able', 'abnormal', 'abnormally'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of words which are present in the Document term matrix\n",
    "WordsVocab=CountVectorizedData.columns[:-1]\n",
    "\n",
    "# Printing sample words\n",
    "WordsVocab[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting every sentence to a numeric vector\n",
    "\n",
    "For each word in a sentence, we extract the numeric form of the word and then simply add all the numeric forms for that sentence to represent the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1424483925.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for word in WordsVocab[CountVecData.iloc[i,:] &gt;= 1]:\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# Defining a function which takes text input and returns one vector for each sentence\n",
    "def FunctionText2Vec(inpTextData):\n",
    "    # Converting the text to numeric data\n",
    "    X = vectorizer.transform(inpTextData)\n",
    "    CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "    W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "    # Looping through each row for the data\n",
    "    for i in range(CountVecData.shape[0]):\n",
    "\n",
    "        # initiating a sentence with all zeros\n",
    "        Sentence = np.zeros(300)\n",
    "\n",
    "        # Looping thru each word in the sentence and if its present in \n",
    "        # the Word2Vec model then storing its vector\n",
    "        for word in WordsVocab[CountVecData.iloc[i,:] &gt;= 1]:\n",
    "            #print(word)\n",
    "            if word in GoogleModel.key_to_index.keys():    \n",
    "                Sentence=Sentence+GoogleModel[word]\n",
    "        # Appending the sentence to the dataframe\n",
    "        W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))\n",
    "    return(W2Vec_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "155\n",
      "386\n",
      "529\n",
      "794\n",
      "1070\n",
      "1231\n",
      "1429\n",
      "1714\n",
      "1740\n",
      "1997\n",
      "2242\n",
      "2683\n",
      "2753\n",
      "3062\n",
      "3457\n",
      "3516\n",
      "3586\n",
      "3695\n",
      "3742\n",
      "3830\n",
      "4047\n",
      "4092\n",
      "4332\n",
      "4335\n",
      "5001\n",
      "5468\n",
      "5473\n",
      "5475\n",
      "5651\n",
      "6040\n",
      "6062\n",
      "6424\n",
      "6673\n",
      "6689\n",
      "6834\n",
      "6922\n",
      "6923\n",
      "7168\n",
      "8201\n",
      "8277\n",
      "8333\n",
      "8360\n",
      "8427\n",
      "8464\n",
      "8518\n",
      "8767\n",
      "9049\n",
      "9050\n",
      "9074\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in range(len(CountVectorizedData.iloc[2,:])):\n",
    "    if CountVectorizedData.iloc[2,:][i]==1:\n",
    "        print(list(CountVectorizedData.iloc[2,:]).index(CountVectorizedData.iloc[2,:][i],i))\n",
    "        sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FunctionText2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Desktop Files\\word files\\NLP with deep learning\\practical1_word2vec.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Desktop%20Files/word%20files/NLP%20with%20deep%20learning/practical1_word2vec.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calling the function to convert all the text data to Word2Vec Vectors\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Desktop%20Files/word%20files/NLP%20with%20deep%20learning/practical1_word2vec.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m W2Vec_Data\u001b[39m=\u001b[39mFunctionText2Vec(TicketData[\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Desktop%20Files/word%20files/NLP%20with%20deep%20learning/practical1_word2vec.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Checking the new representation for sentences\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Desktop%20Files/word%20files/NLP%20with%20deep%20learning/practical1_word2vec.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m W2Vec_Data\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FunctionText2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "# Calling the function to convert all the text data to Word2Vec Vectors\n",
    "W2Vec_Data=FunctionText2Vec(TicketData['body'])\n",
    " \n",
    "# Checking the new representation for sentences\n",
    "W2Vec_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19796, 9100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t\n",
    "# Comparing the above with the document term matrix\n",
    "CountVectorizedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding the target variable\n",
    "W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data['Priority']=CountVectorizedData['Priority']\n",
    " \n",
    "# Assigning to DataForML variable\n",
    "DataForML=W2Vec_Data\n",
    "DataForML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=DataForML.columns[-1]\n",
    "Predictors=DataForML.columns[:-1]\n",
    "\n",
    "X=DataForML[Predictors].values\n",
    "y=DataForML[TargetVariable].values\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)\n",
    "\n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Choose either standardization or Normalization\n",
    "# On this data Min Max Normalization is used because we need to fit Naive Bayes\n",
    "\n",
    "# Choose between standardization and MinMAx normalization\n",
    "#PredictorScaler=StandardScaler()\n",
    "PredictorScaler=MinMaxScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "\n",
    "# Generating the standardized values of X\n",
    "X=PredictorScalerFit.transform(X)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)\n",
    "\n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# GaussianNB is used in Binomial Classification\n",
    "# MultinomialNB is used in multi-class classification\n",
    "#clf = GaussianNB()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Printing all the parameters of Naive Bayes\n",
    "print(clf)\n",
    "\n",
    "NB=clf.fit(X_train,y_train)\n",
    "prediction=NB.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(NB, X , y, cv=5, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 5-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f47da164e37bfb80af0a2f458b41edc2e67d49677a6b1deb6af6e4195914aac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
